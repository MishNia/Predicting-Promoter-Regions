{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjVL09cMJ11Z",
        "outputId": "ff1f81a6-bc23-4cfe-876b-ccee3b1be506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1uqXcMXJsAE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import itertools\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import math\n",
        "import argparse\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "G2srD2gLLDhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reader(filep):\n",
        "  with open(filep, \"r\") as f:\n",
        "    data = f.readlines()\n",
        "  data = [da.strip() for da in data]\n",
        "  return data\n",
        "\n",
        "\n",
        "def get_list_kmer(kmer, string=\"TGCA\"):\n",
        "  string = list(string)\n",
        "  lkmer = [\"\".join(p) for p in itertools.product(string, repeat=kmer)]\n",
        "  lkmer.sort()\n",
        "  return lkmer\n",
        "\n",
        "\n",
        "def protein2num(protein, elements):\n",
        "  kmer = len(elements[0])\n",
        "  edict = dict()\n",
        "  for i, ele in enumerate(elements):\n",
        "    edict[ele] = i\n",
        "  token = list()\n",
        "  for i in range(len(protein)-kmer+1):\n",
        "    try:\n",
        "      token.append(edict[protein[i:i+kmer]])\n",
        "    except KeyError:\n",
        "      token.append(0)\n",
        "      print(\"Key error : \", protein[i:i+kmer], i)\n",
        "  return token\n",
        "\n",
        "\n",
        "def neggen(protein, num_part=20, keep=8, max_class=4):\n",
        "  length = len(protein)\n",
        "  # get part\n",
        "  part_len = length // num_part\n",
        "  if part_len * num_part < length:\n",
        "    num_part += 1\n",
        "\n",
        "  iterator = np.arange(num_part)\n",
        "  keep_parts = random.sample(list(iterator), k=keep)\n",
        "\n",
        "  outpro = list()\n",
        "  for it in iterator:\n",
        "    start = it * part_len\n",
        "    pro_part = protein[start:start + part_len]\n",
        "    if it in keep_parts:\n",
        "      outpro.extend(pro_part)\n",
        "    else:\n",
        "      pro_part = random.choices(np.arange(max_class), k=len(pro_part))\n",
        "      outpro.extend(pro_part)\n",
        "  return outpro"
      ],
      "metadata": {
        "id": "M1I1ss3aJ_Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LoadOnehot(Dataset):\n",
        "  def __init__(self, pathpos, is_pos=True, device=\"cuda\", fake=0, length_pro=300, divide=20, part=8):\n",
        "    \"\"\"\n",
        "    Dataset\n",
        "    :param pathpos: Path to the txt data file\n",
        "    :param is_pos: Control the label for dataset True for 1, False for 0\n",
        "    :param device: Device\n",
        "    :param fake: 0 for load original txt dataset , 1 for random fake, 2 for faking method as describe in the paper\n",
        "    :param length_pro: Input sequence length\n",
        "    :param divide: Number of part to break protein into before replace some part with random sequence\n",
        "    :param part: Number of part to keep the same when do random subsequence\n",
        "    \"\"\"\n",
        "    if is_pos and fake != 0:\n",
        "      raise Exception(\"Cant use key word fake on positive dataset\")\n",
        "    self.device = device\n",
        "    self.fake = fake\n",
        "    self.length_pro = length_pro\n",
        "    self.divide = divide\n",
        "    self.part = part\n",
        "\n",
        "    # get list of kmer\n",
        "    dic = get_list_kmer(1)\n",
        "\n",
        "    # read data from file\n",
        "    self.dpos = reader(pathpos)\n",
        "\n",
        "    # convert protein to number sequence\n",
        "    self.npos = [protein2num(pro, dic) for pro in self.dpos]\n",
        "\n",
        "    if is_pos:\n",
        "      self.poslabel = torch.from_numpy(np.ones(len(self.dpos)))\n",
        "    else:\n",
        "      # ic(\"go false\")\n",
        "      self.poslabel = torch.from_numpy(np.zeros(len(self.dpos)))\n",
        "    self.poslabel = self.poslabel.to(device)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dpos)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # convert data to one hot format and up to device\n",
        "    pro = self.npos[idx]\n",
        "    if len(pro) < self.length_pro:\n",
        "      pro = pro + [0] * (self.length_pro - len(pro))\n",
        "    elif len(pro) > self.length_pro:\n",
        "      pro = pro[:self.length_pro]\n",
        "\n",
        "    # random generate a fake promoter by shuffle the pro\n",
        "    if self.fake == 1:\n",
        "      pro = random.shuffle(pro)\n",
        "    # random generate a fake promoter by replace part of pro\n",
        "    elif self.fake == 2:\n",
        "      pro = neggen(pro, num_part=self.divide, keep=self.part, max_class=4)\n",
        "\n",
        "    torchpro = torch.from_numpy(np.array(pro))\n",
        "    onehot = torch.nn.functional.one_hot(torchpro, num_classes=4).to(self.device)\n",
        "    return onehot.float(), self.poslabel[idx]"
      ],
      "metadata": {
        "id": "mtsXPn1LKoLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_path, train_potion=0.8, rand_neg=False, batch_size=32, num_cpu=0, device=\"cuda\"):\n",
        "  \"\"\"\n",
        "  Load all data\n",
        "  :param data_path: Path to txt file contain promoter (1 DNA promoter on 1 line)\n",
        "  :param train_potion: The potion of dataset spend for training\n",
        "  :param rand_neg: Add random of DNA to negative datset\n",
        "  :param batch_size: Batch size for loader\n",
        "  :param num_cpu: Number of CPU perform load data in prallel\n",
        "  :param device: Device to load data on\n",
        "  :return: List of train, val, test dataset for positive and negative datset\n",
        "  \"\"\"\n",
        "  # get dataset\n",
        "  manual_seed = torch.Generator().manual_seed(42)\n",
        "  pos_data = LoadOnehot(data_path, device=device)\n",
        "  neg_data = LoadOnehot(data_path, is_pos=False, fake=2, device=device)\n",
        "\n",
        "  # calculate the size of train and test dataset\n",
        "  train_num = int(len(pos_data)*train_potion)\n",
        "  val_num = int(len(pos_data)*(1-train_potion)*0.5)\n",
        "  split_size = [train_num, val_num, len(pos_data) - train_num - val_num]\n",
        "\n",
        "  # split dataset\n",
        "  train_pos, val_pos, test_pos = random_split(pos_data, split_size, generator=manual_seed)\n",
        "  train_neg, val_neg, test_neg = random_split(neg_data, split_size, generator=manual_seed)\n",
        "\n",
        "  # add random dataset to negative dataset(only to train set)\n",
        "  if rand_neg:\n",
        "    neg_data_rand = LoadOnehot(data_path, is_pos=False, fake=1, device=device)\n",
        "    train_neg = ConcatDataset([train_neg, neg_data_rand])\n",
        "\n",
        "  # data loader\n",
        "  stack_dataset = [train_pos, val_pos, test_pos, train_neg, val_neg, test_neg]\n",
        "  stack_loaders = list()\n",
        "  for dataset in stack_dataset:\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_cpu)\n",
        "    stack_loaders.append(data_loader)\n",
        "\n",
        "  return stack_loaders"
      ],
      "metadata": {
        "id": "9GLVqpohKrYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_test(data_path, batch_size=32, device=\"cuda\", num_cpu=0):\n",
        "  dataset = LoadOnehot(data_path, device=device)\n",
        "  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_cpu)\n",
        "  return data_loader"
      ],
      "metadata": {
        "id": "XX32IszfKtya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ParallelCNN(nn.Module):\n",
        "  def __init__(self, para_ker, pool_kernel=6, drop=0.5):\n",
        "    \"\"\"\n",
        "    Multiple CNN layer apply on input and concatenate the output\n",
        "    :param para_ker: List of kernel size that will be used\n",
        "    :param pool_kernel: Pooling parameter after CNN\n",
        "    :param drop: Dropout parameter\n",
        "    \"\"\"\n",
        "    super(ParallelCNN, self).__init__()\n",
        "    self.lseq = nn.ModuleList()\n",
        "    for k in para_ker:\n",
        "      seq = nn.Sequential(\n",
        "        nn.Conv1d(4, 4, kernel_size=k, padding=\"same\"),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool1d(pool_kernel),\n",
        "        nn.Dropout(drop)\n",
        "      )\n",
        "      self.lseq.append(seq)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    \"\"\"\n",
        "    :param inputs: DNA onehot sequences [batch_size x 4 x length]\n",
        "    :return: Stack CNN output feature from different kernel size [batch_size x 12 x length]\n",
        "    \"\"\"\n",
        "    _x = list()\n",
        "    for seq in self.lseq:\n",
        "      x = seq(inputs)\n",
        "      _x.append(x)\n",
        "    # concate outputs of every conv layer to a tensor\n",
        "    _x = torch.cat(_x, 1)\n",
        "    return _x"
      ],
      "metadata": {
        "id": "6jOaIk2HLLbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BidirectionalLSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(BidirectionalLSTM, self).__init__()\n",
        "    self.rnn = nn.LSTM(input_size, hidden_size, bidirectional=True, batch_first=True)\n",
        "    self.linear = nn.Linear(hidden_size * 2, output_size)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    \"\"\"\n",
        "    :param inputs: visual feature [batch_size x T x input_size]\n",
        "    :return: contextual feature [batch_size x T x output_size]\n",
        "    \"\"\"\n",
        "\n",
        "    self.rnn.flatten_parameters()\n",
        "    recurrent, _ = self.rnn(inputs)  # batch_size x T x input_size -> batch_size x T x (2*hidden_size)\n",
        "    output = self.linear(recurrent)  # batch_size x T x output_size\n",
        "    return output"
      ],
      "metadata": {
        "id": "ZpMjSRUhLRHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeePromoter(nn.Module):\n",
        "  def __init__(self, para_ker, input_shape=(64, 300, 4), pool_kernel=6, drop=0.5):\n",
        "    \"\"\"\n",
        "    Deepromoter\n",
        "    :param para_ker: List of kernel size that will be used\n",
        "    :param input_shape: Specifies the input shape for model(fixed)\n",
        "    :param pool_kernel: Pooling parameter after CNN\n",
        "    :param drop: Dropout parameter\n",
        "    \"\"\"\n",
        "    super(DeePromoter, self).__init__()\n",
        "    binode = len(para_ker) * 4\n",
        "\n",
        "    self.pconv = ParallelCNN(para_ker, pool_kernel, drop)\n",
        "    self.bilstm = BidirectionalLSTM(binode, binode, binode)\n",
        "    self.flatten = nn.Flatten()\n",
        "    x = torch.zeros(input_shape)\n",
        "    shape = self.get_feature_shape(x)\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "      nn.Linear(shape, shape),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(shape, 2),\n",
        "      nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def get_feature_shape(self, x):\n",
        "    \"\"\"Pass a dummy input through to find the shape\n",
        "    after flatten layer for Linear layer construction\"\"\"\n",
        "    x = x.permute(0, 2, 1)\n",
        "    x = self.pconv(x)\n",
        "    x = x.permute(0, 2, 1)\n",
        "    x = self.bilstm(x)\n",
        "    x = self.flatten(x)\n",
        "    return x.shape[1]\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.permute(0, 2, 1)\n",
        "    x = self.pconv(x)\n",
        "    x = x.permute(0, 2, 1)\n",
        "    x = self.bilstm(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "YiJpX9CzMSog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(net, loaders):\n",
        "  \"\"\"\n",
        "  Infer and check results against labels\n",
        "  :param net: Model object in eval state\n",
        "  :param loaders: List of torch dataloader for infer\n",
        "  :return: List of [correct, total] for every dataloader, list of predicted results in int type\n",
        "  \"\"\"\n",
        "  eval_result = list()\n",
        "  ltotal = list()\n",
        "  lcorrect = list()\n",
        "  pred_result = list()\n",
        "  for load in loaders:\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    pred_list = list()\n",
        "    for data in load:\n",
        "      inputs = data[0]\n",
        "      labels = data[1]\n",
        "      outputs = net(inputs)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      pred_list += list(predicted.cpu().numpy())\n",
        "    acc = correct/total\n",
        "    eval_result.append(acc)\n",
        "    lcorrect.append(correct)\n",
        "    ltotal.append(total)\n",
        "    pred_result.append(pred_list)\n",
        "  return (lcorrect, ltotal), pred_result"
      ],
      "metadata": {
        "id": "fpmiZtY_MZTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mcc(data):\n",
        "  \"\"\"\n",
        "  Calculate Matthew correlation coeficient\n",
        "  :param data: List output of evaluate with the first item is positive result and second item is negative result\n",
        "  :return: Precision, recall, MCC\n",
        "  \"\"\"\n",
        "  pos_count = data[0][0]\n",
        "  neg_count = data[0][1]\n",
        "\n",
        "  tol_pos_count = data[1][0]\n",
        "  tol_neg_count = data[1][1]\n",
        "\n",
        "  TP = pos_count\n",
        "  FN = tol_pos_count - pos_count\n",
        "  TN = neg_count\n",
        "  FP = tol_neg_count - neg_count\n",
        "\n",
        "  precision = TP / (TP + FP)\n",
        "  recall = TP / (TP + FN)\n",
        "  MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
        "\n",
        "  return precision, recall, MCC"
      ],
      "metadata": {
        "id": "mTNEUWx4MfTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(data_path, pretrain, ker=None):\n",
        "  if ker is None:\n",
        "    ker = [27, 14, 7]\n",
        "\n",
        "  dataloader = load_data_test(data_path, device=device)\n",
        "\n",
        "  # model define\n",
        "  net = DeePromoter(ker)\n",
        "  net.to(device)\n",
        "\n",
        "  net.load_state_dict(torch.load(pretrain))\n",
        "\n",
        "  net.eval()\n",
        "  eval_data, results = evaluate(net, [dataloader])\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "IAaVDmSFMiIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_main():\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument(\n",
        "    \"-d\",\n",
        "    \"--data\",\n",
        "    type=str,\n",
        "    required=True,\n",
        "    help=\"path to dataset(txt file)\",\n",
        "  )\n",
        "  parser.add_argument(\"-w\", \"--weight\", type=str, help=\"Path to pre-train\")\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  output = test(args.data, args.weight)\n",
        "\n",
        "  with open(\"infer_results.txt\", \"w\") as f:\n",
        "    for out in output[0]:\n",
        "      f.write(str(out) + \"\\n\")"
      ],
      "metadata": {
        "id": "rjX_KyVCMlFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "zwZMjEgnNjYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_path, pretrain=None, exp_name=\"test\", training=True, ker=None, epoch_num=1000):\n",
        "  \"\"\"\n",
        "  Training\n",
        "  :param data_path: Path to the txt data file\n",
        "  :param pretrain: Path to weight for continue training\n",
        "  :param exp_name: Folder name to save the results\n",
        "  :param training: If False, performs testing only\n",
        "  :param ker: List kernel size of list CNN applying to the protein sequence\n",
        "  :param epoch_num: Max epoch to train\n",
        "  \"\"\"\n",
        "  if ker is None:\n",
        "    ker = [27, 14, 7]\n",
        "\n",
        "  # create the experiment folder to save the result\n",
        "  output = Path(\"./output\")\n",
        "  output.mkdir(exist_ok=True)\n",
        "  exp_folder = output.joinpath(exp_name)\n",
        "  exp_folder.mkdir(exist_ok=True)\n",
        "\n",
        "  # load data\n",
        "  print(\"Data loading\")\n",
        "  data = load_data(data_path, device=device)\n",
        "  train_pos, val_pos, test_pos, train_neg, val_neg, test_neg = data\n",
        "\n",
        "  # model define\n",
        "  net = DeePromoter(ker)\n",
        "  net.to(device)\n",
        "\n",
        "  # load pre-train model\n",
        "  if pretrain is not None:\n",
        "    net.load_state_dict(torch.load(pretrain))\n",
        "\n",
        "  # define loss, optimizer\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  # optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "  optimizer = optim.Adam(net.parameters(), lr=0.00001)\n",
        "\n",
        "  running_loss = 0\n",
        "  best_mcc = 0\n",
        "  best_precision = 0\n",
        "  best_recall = 0\n",
        "  break_after = 10\n",
        "  last_update_best = 0\n",
        "  pbar = range(epoch_num)\n",
        "  print(\"Start training\")\n",
        "  if training:\n",
        "    for epoch in pbar:\n",
        "      for i, (batch_pos, batch_neg) in enumerate(zip(train_pos, train_neg)):\n",
        "        inputs = torch.cat((batch_pos[0], batch_neg[0]), dim=0)\n",
        "        labels = torch.cat((batch_pos[1], batch_neg[1]), dim=0)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # pass model to\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "      if epoch % 10 == 0:\n",
        "        torch.save(net.state_dict(), str(exp_folder.joinpath(\"epoch_\" + str(epoch) + \".pth\")))\n",
        "        net.eval()\n",
        "        eval_data, _ = evaluate(net, [val_pos, val_neg])\n",
        "        precision, recall, MCC = mcc(eval_data)\n",
        "        net.train()\n",
        "        print(\"Epoch :\", epoch, \"Experiment :\", exp_name)\n",
        "        print(\"precision :\", precision)\n",
        "        print(\"recall :\", recall)\n",
        "        print(\"MCC :\", MCC)\n",
        "\n",
        "        # save best model\n",
        "        if precision > best_precision:\n",
        "          best_precision = precision\n",
        "          print(\"Update best precision\")\n",
        "          torch.save(net.state_dict(), str(exp_folder.joinpath(\"best_precision.pth\")))\n",
        "        if recall > best_recall:\n",
        "          best_recall = recall\n",
        "          print(\"Update best recall\")\n",
        "          torch.save(net.state_dict(), str(exp_folder.joinpath(\"best_recall.pth\")))\n",
        "        if MCC > best_mcc:\n",
        "          print(\"Update best MCC\")\n",
        "          best_mcc = MCC\n",
        "          torch.save(net.state_dict(), str(exp_folder.joinpath(\"best_mcc.pth\")))\n",
        "          last_update_best = 0\n",
        "        else:\n",
        "          last_update_best += 1\n",
        "        if last_update_best >= break_after:\n",
        "          break\n",
        "      if last_update_best >= break_after:\n",
        "        break\n",
        "\n",
        "    # test\n",
        "    best_model = str(exp_folder.joinpath(\"best_mcc.pth\"))\n",
        "    net.load_state_dict(torch.load(best_model))\n",
        "    net.eval()\n",
        "    eval_data, _ = evaluate(net, [test_pos, test_neg])\n",
        "    precision, recall, MCC = mcc(eval_data)\n",
        "    print(\"precision :\", precision)\n",
        "    print(\"recall :\", recall)\n",
        "    print(\"MCC :\", MCC)\n",
        "    with open(str(exp_folder.joinpath(\"log.txt\")), \"w\") as f:\n",
        "      f.write(f\"Test precision: {precision}\\n\")\n",
        "      f.write(f\"Test recall: {recall}\\n\")\n",
        "      f.write(f\"Test MCC : {MCC}\\n\")"
      ],
      "metadata": {
        "id": "lV9rSDiSNg3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train('/content/drive/MyDrive/data/human/TATA/hs_pos_TATA.txt', exp_name=\"human_TATA\", training=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89B37VmOPGro",
        "outputId": "fa42abf2-e9e1-472d-ea9e-03b2e1c7de40"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loading\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:370: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1036.)\n",
            "  return F.conv1d(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training\n",
            "Epoch : 0 Experiment : human_TATA\n",
            "precision : 0.7281553398058253\n",
            "recall : 0.2568493150684932\n",
            "MCC : 0.2111575952326206\n",
            "Update best precision\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 10 Experiment : human_TATA\n",
            "precision : 0.7286432160804021\n",
            "recall : 0.4965753424657534\n",
            "MCC : 0.3287641768278304\n",
            "Update best precision\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 20 Experiment : human_TATA\n",
            "precision : 0.79375\n",
            "recall : 0.4349315068493151\n",
            "MCC : 0.3608983811399463\n",
            "Update best precision\n",
            "Update best MCC\n",
            "Epoch : 30 Experiment : human_TATA\n",
            "precision : 0.8275862068965517\n",
            "recall : 0.410958904109589\n",
            "MCC : 0.3765367277077475\n",
            "Update best precision\n",
            "Update best MCC\n",
            "Epoch : 40 Experiment : human_TATA\n",
            "precision : 0.8266666666666667\n",
            "recall : 0.4246575342465753\n",
            "MCC : 0.38409228281811403\n",
            "Update best MCC\n",
            "Epoch : 50 Experiment : human_TATA\n",
            "precision : 0.8641975308641975\n",
            "recall : 0.4794520547945205\n",
            "MCC : 0.4513030562052148\n",
            "Update best precision\n",
            "Update best MCC\n",
            "Epoch : 60 Experiment : human_TATA\n",
            "precision : 0.8789473684210526\n",
            "recall : 0.571917808219178\n",
            "MCC : 0.5263051027501737\n",
            "Update best precision\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 70 Experiment : human_TATA\n",
            "precision : 0.8647342995169082\n",
            "recall : 0.613013698630137\n",
            "MCC : 0.5405316138836923\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 80 Experiment : human_TATA\n",
            "precision : 0.8564593301435407\n",
            "recall : 0.613013698630137\n",
            "MCC : 0.5322277216449743\n",
            "Epoch : 90 Experiment : human_TATA\n",
            "precision : 0.8537735849056604\n",
            "recall : 0.6198630136986302\n",
            "MCC : 0.5341360109089501\n",
            "Update best recall\n",
            "Epoch : 100 Experiment : human_TATA\n",
            "precision : 0.8611111111111112\n",
            "recall : 0.636986301369863\n",
            "MCC : 0.5533167449931865\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 110 Experiment : human_TATA\n",
            "precision : 0.8726415094339622\n",
            "recall : 0.6335616438356164\n",
            "MCC : 0.5626232648240941\n",
            "Update best MCC\n",
            "Epoch : 120 Experiment : human_TATA\n",
            "precision : 0.9018691588785047\n",
            "recall : 0.660958904109589\n",
            "MCC : 0.6112525701138818\n",
            "Update best precision\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 130 Experiment : human_TATA\n",
            "precision : 0.8508771929824561\n",
            "recall : 0.6643835616438356\n",
            "MCC : 0.5616005961955094\n",
            "Update best recall\n",
            "Epoch : 140 Experiment : human_TATA\n",
            "precision : 0.8755555555555555\n",
            "recall : 0.6746575342465754\n",
            "MCC : 0.594631923738699\n",
            "Update best recall\n",
            "Epoch : 150 Experiment : human_TATA\n",
            "precision : 0.953125\n",
            "recall : 0.6267123287671232\n",
            "MCC : 0.6342428798277872\n",
            "Update best precision\n",
            "Update best MCC\n",
            "Epoch : 160 Experiment : human_TATA\n",
            "precision : 0.9252336448598131\n",
            "recall : 0.678082191780822\n",
            "MCC : 0.6467905102367819\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 170 Experiment : human_TATA\n",
            "precision : 0.9045454545454545\n",
            "recall : 0.6815068493150684\n",
            "MCC : 0.6290106085387953\n",
            "Update best recall\n",
            "Epoch : 180 Experiment : human_TATA\n",
            "precision : 0.9357798165137615\n",
            "recall : 0.6986301369863014\n",
            "MCC : 0.6726432857191329\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 190 Experiment : human_TATA\n",
            "precision : 0.9237668161434978\n",
            "recall : 0.7054794520547946\n",
            "MCC : 0.6661250589709387\n",
            "Update best recall\n",
            "Epoch : 200 Experiment : human_TATA\n",
            "precision : 0.9484978540772532\n",
            "recall : 0.7568493150684932\n",
            "MCC : 0.7308273089915175\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 210 Experiment : human_TATA\n",
            "precision : 0.9218106995884774\n",
            "recall : 0.7671232876712328\n",
            "MCC : 0.7121533716308227\n",
            "Update best recall\n",
            "Epoch : 220 Experiment : human_TATA\n",
            "precision : 0.9227467811158798\n",
            "recall : 0.7363013698630136\n",
            "MCC : 0.6888659323987031\n",
            "Epoch : 230 Experiment : human_TATA\n",
            "precision : 0.9504132231404959\n",
            "recall : 0.7876712328767124\n",
            "MCC : 0.757767120966401\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 240 Experiment : human_TATA\n",
            "precision : 0.9322709163346613\n",
            "recall : 0.8013698630136986\n",
            "MCC : 0.7505865127891055\n",
            "Update best recall\n",
            "Epoch : 250 Experiment : human_TATA\n",
            "precision : 0.9551020408163265\n",
            "recall : 0.8013698630136986\n",
            "MCC : 0.7737879668947788\n",
            "Update best precision\n",
            "Update best MCC\n",
            "Epoch : 260 Experiment : human_TATA\n",
            "precision : 0.9182879377431906\n",
            "recall : 0.8082191780821918\n",
            "MCC : 0.7416483279103844\n",
            "Update best recall\n",
            "Epoch : 270 Experiment : human_TATA\n",
            "precision : 0.915057915057915\n",
            "recall : 0.8116438356164384\n",
            "MCC : 0.7410489519279744\n",
            "Update best recall\n",
            "Epoch : 280 Experiment : human_TATA\n",
            "precision : 0.9137254901960784\n",
            "recall : 0.797945205479452\n",
            "MCC : 0.7284746041029388\n",
            "Epoch : 290 Experiment : human_TATA\n",
            "precision : 0.9250936329588015\n",
            "recall : 0.8458904109589042\n",
            "MCC : 0.7802622493765766\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 300 Experiment : human_TATA\n",
            "precision : 0.956\n",
            "recall : 0.8184931506849316\n",
            "MCC : 0.7890265358348204\n",
            "Update best precision\n",
            "Update best MCC\n",
            "Epoch : 310 Experiment : human_TATA\n",
            "precision : 0.9360902255639098\n",
            "recall : 0.8527397260273972\n",
            "MCC : 0.7976890061348133\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 320 Experiment : human_TATA\n",
            "precision : 0.9360902255639098\n",
            "recall : 0.8527397260273972\n",
            "MCC : 0.7976890061348133\n",
            "Epoch : 330 Experiment : human_TATA\n",
            "precision : 0.9647058823529412\n",
            "recall : 0.8424657534246576\n",
            "MCC : 0.8182392472625427\n",
            "Update best precision\n",
            "Update best MCC\n",
            "Epoch : 340 Experiment : human_TATA\n",
            "precision : 0.937037037037037\n",
            "recall : 0.8664383561643836\n",
            "MCC : 0.8105229134658228\n",
            "Update best recall\n",
            "Epoch : 350 Experiment : human_TATA\n",
            "precision : 0.9465648854961832\n",
            "recall : 0.8493150684931506\n",
            "MCC : 0.8056330530626206\n",
            "Epoch : 360 Experiment : human_TATA\n",
            "precision : 0.9578544061302682\n",
            "recall : 0.8561643835616438\n",
            "MCC : 0.8231450788510758\n",
            "Update best MCC\n",
            "Epoch : 370 Experiment : human_TATA\n",
            "precision : 0.9433962264150944\n",
            "recall : 0.8561643835616438\n",
            "MCC : 0.8082572032653899\n",
            "Epoch : 380 Experiment : human_TATA\n",
            "precision : 0.9505703422053232\n",
            "recall : 0.8561643835616438\n",
            "MCC : 0.8156765099375703\n",
            "Epoch : 390 Experiment : human_TATA\n",
            "precision : 0.948905109489051\n",
            "recall : 0.8904109589041096\n",
            "MCC : 0.8440709989029801\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 400 Experiment : human_TATA\n",
            "precision : 0.929368029739777\n",
            "recall : 0.8561643835616438\n",
            "MCC : 0.793561451276253\n",
            "Epoch : 410 Experiment : human_TATA\n",
            "precision : 0.9333333333333333\n",
            "recall : 0.863013698630137\n",
            "MCC : 0.8036540752161124\n",
            "Epoch : 420 Experiment : human_TATA\n",
            "precision : 0.9548872180451128\n",
            "recall : 0.8698630136986302\n",
            "MCC : 0.832072152950969\n",
            "Epoch : 430 Experiment : human_TATA\n",
            "precision : 0.945054945054945\n",
            "recall : 0.8835616438356164\n",
            "MCC : 0.8339591068816351\n",
            "Epoch : 440 Experiment : human_TATA\n",
            "precision : 0.9543726235741445\n",
            "recall : 0.8595890410958904\n",
            "MCC : 0.8225598560129929\n",
            "Epoch : 450 Experiment : human_TATA\n",
            "precision : 0.935251798561151\n",
            "recall : 0.8904109589041096\n",
            "MCC : 0.8297213299089478\n",
            "Epoch : 460 Experiment : human_TATA\n",
            "precision : 0.969811320754717\n",
            "recall : 0.8801369863013698\n",
            "MCC : 0.8564086962258812\n",
            "Update best precision\n",
            "Update best MCC\n",
            "Epoch : 470 Experiment : human_TATA\n",
            "precision : 0.9363295880149812\n",
            "recall : 0.8561643835616438\n",
            "MCC : 0.8008859211662659\n",
            "Epoch : 480 Experiment : human_TATA\n",
            "precision : 0.9622641509433962\n",
            "recall : 0.8732876712328768\n",
            "MCC : 0.842651126808598\n",
            "Epoch : 490 Experiment : human_TATA\n",
            "precision : 0.9588014981273408\n",
            "recall : 0.8767123287671232\n",
            "MCC : 0.8421332647456444\n",
            "Epoch : 500 Experiment : human_TATA\n",
            "precision : 0.9659090909090909\n",
            "recall : 0.8732876712328768\n",
            "MCC : 0.8463658944408897\n",
            "Epoch : 510 Experiment : human_TATA\n",
            "precision : 0.9628252788104089\n",
            "recall : 0.886986301369863\n",
            "MCC : 0.8553974085185584\n",
            "Epoch : 520 Experiment : human_TATA\n",
            "precision : 0.9343065693430657\n",
            "recall : 0.8767123287671232\n",
            "MCC : 0.8166215355240214\n",
            "Epoch : 530 Experiment : human_TATA\n",
            "precision : 0.9518518518518518\n",
            "recall : 0.8801369863013698\n",
            "MCC : 0.8379982664646642\n",
            "Epoch : 540 Experiment : human_TATA\n",
            "precision : 0.948905109489051\n",
            "recall : 0.8904109589041096\n",
            "MCC : 0.8440709989029801\n",
            "Epoch : 550 Experiment : human_TATA\n",
            "precision : 0.9252669039145908\n",
            "recall : 0.8904109589041096\n",
            "MCC : 0.8190745402862489\n",
            "Epoch : 560 Experiment : human_TATA\n",
            "precision : 0.9592592592592593\n",
            "recall : 0.886986301369863\n",
            "MCC : 0.851735942964085\n",
            "precision : 0.9548872180451128\n",
            "recall : 0.8639455782312925\n",
            "MCC : 0.8268878523061103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-e5b8bbb196de>:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(best_model))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saved epoch 560 as best path. using this for testing"
      ],
      "metadata": {
        "id": "6gqYXpBPU5G0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "o4t8UJDGU96d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test('/content/drive/MyDrive/data/human/TATA/hs_pos_TATA.txt', pretrain = '/content/output/human_TATA/epoch_560.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a12GorbDRKbU",
        "outputId": "d10c1a1b-e318-4564-b607-0014f1efeb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-c10a607ddafe>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(pretrain))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  ...]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Human Non TATA"
      ],
      "metadata": {
        "id": "YI2CI-8vVv8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train('/content/drive/MyDrive/data/human/nonTATA/hs_pos_nonTATA.txt', exp_name=\"human_non_TATA\", training=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEnjw1wIVmKf",
        "outputId": "5a8693d9-d15b-4103-833f-9bbe68a360db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loading\n",
            "Key error :  N 200\n",
            "Key error :  N 200\n",
            "Start training\n",
            "Epoch : 0 Experiment : human_non_TATA\n",
            "precision : 0.8718980549966465\n",
            "recall : 0.5017367811655732\n",
            "MCC : 0.4727382049857469\n",
            "Update best precision\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 10 Experiment : human_non_TATA\n",
            "precision : 0.9102202145680407\n",
            "recall : 0.6221536086453107\n",
            "MCC : 0.5911742022606917\n",
            "Update best precision\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 20 Experiment : human_non_TATA\n",
            "precision : 0.92253136933988\n",
            "recall : 0.6526437668853724\n",
            "MCC : 0.625190847473307\n",
            "Update best precision\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 30 Experiment : human_non_TATA\n",
            "precision : 0.9396267837541163\n",
            "recall : 0.6607487456580471\n",
            "MCC : 0.6474685631153649\n",
            "Update best precision\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 40 Experiment : human_non_TATA\n",
            "precision : 0.9551924090669478\n",
            "recall : 0.6993438826707835\n",
            "MCC : 0.6918166104549979\n",
            "Update best precision\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 50 Experiment : human_non_TATA\n",
            "precision : 0.9711229946524064\n",
            "recall : 0.700887688151293\n",
            "MCC : 0.7080108884919442\n",
            "Update best precision\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 60 Experiment : human_non_TATA\n",
            "precision : 0.9738298943130347\n",
            "recall : 0.7468159011964492\n",
            "MCC : 0.7473360894989421\n",
            "Update best precision\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 70 Experiment : human_non_TATA\n",
            "precision : 0.9782057780030411\n",
            "recall : 0.7448861443458125\n",
            "MCC : 0.7499347860259772\n",
            "Update best precision\n",
            "Update best MCC\n",
            "Epoch : 80 Experiment : human_non_TATA\n",
            "precision : 0.9692020531964536\n",
            "recall : 0.8016209957545349\n",
            "MCC : 0.7880170877302297\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 90 Experiment : human_non_TATA\n",
            "precision : 0.9740673339399454\n",
            "recall : 0.8263218834426862\n",
            "MCC : 0.813737745171082\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 100 Experiment : human_non_TATA\n",
            "precision : 0.9808946877912396\n",
            "recall : 0.8124276341181011\n",
            "MCC : 0.8086190164933847\n",
            "Update best precision\n",
            "Epoch : 110 Experiment : human_non_TATA\n",
            "precision : 0.9650597080937638\n",
            "recall : 0.8421458896179081\n",
            "MCC : 0.8183200893631917\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 120 Experiment : human_non_TATA\n",
            "precision : 0.9762118491921006\n",
            "recall : 0.8394442300270166\n",
            "MCC : 0.8271466988788873\n",
            "Update best MCC\n",
            "Epoch : 130 Experiment : human_non_TATA\n",
            "precision : 0.9691629955947136\n",
            "recall : 0.8490930142802007\n",
            "MCC : 0.8284589413221105\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 140 Experiment : human_non_TATA\n",
            "precision : 0.9760213143872114\n",
            "recall : 0.8483211115399459\n",
            "MCC : 0.8346545740915824\n",
            "Update best MCC\n",
            "Epoch : 150 Experiment : human_non_TATA\n",
            "precision : 0.9696581196581197\n",
            "recall : 0.8757236588189888\n",
            "MCC : 0.8523298974296636\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 160 Experiment : human_non_TATA\n",
            "precision : 0.9716404886561955\n",
            "recall : 0.8595137012736396\n",
            "MCC : 0.8400390238400732\n",
            "Epoch : 170 Experiment : human_non_TATA\n",
            "precision : 0.9760452961672473\n",
            "recall : 0.8649170204554226\n",
            "MCC : 0.8492118629847083\n",
            "Epoch : 180 Experiment : human_non_TATA\n",
            "precision : 0.9724612736660929\n",
            "recall : 0.8722500964878426\n",
            "MCC : 0.852085473988979\n",
            "Epoch : 190 Experiment : human_non_TATA\n",
            "precision : 0.9727311461440137\n",
            "recall : 0.8811269780007719\n",
            "MCC : 0.8602490977966856\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 200 Experiment : human_non_TATA\n",
            "precision : 0.972422571064913\n",
            "recall : 0.8846005403319182\n",
            "MCC : 0.8630405463302144\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 210 Experiment : human_non_TATA\n",
            "precision : 0.9702633814783348\n",
            "recall : 0.8815129293708993\n",
            "MCC : 0.8580936432353079\n",
            "Epoch : 220 Experiment : human_non_TATA\n",
            "precision : 0.9698000850701829\n",
            "recall : 0.8799691238903898\n",
            "MCC : 0.8562477960151949\n",
            "Epoch : 230 Experiment : human_non_TATA\n",
            "precision : 0.9727659574468085\n",
            "recall : 0.882284832111154\n",
            "MCC : 0.8613179517553943\n",
            "Epoch : 240 Experiment : human_non_TATA\n",
            "precision : 0.9704142011834319\n",
            "recall : 0.8861443458124276\n",
            "MCC : 0.8623855374617773\n",
            "Update best recall\n",
            "Epoch : 250 Experiment : human_non_TATA\n",
            "precision : 0.970787468247248\n",
            "recall : 0.8849864917020456\n",
            "MCC : 0.8617281537173627\n",
            "Epoch : 260 Experiment : human_non_TATA\n",
            "precision : 0.9697097181320993\n",
            "recall : 0.8896179081435739\n",
            "MCC : 0.8647841067122404\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 270 Experiment : human_non_TATA\n",
            "precision : 0.9769427839453458\n",
            "recall : 0.8830567348514087\n",
            "MCC : 0.866224680272974\n",
            "Update best MCC\n",
            "Epoch : 280 Experiment : human_non_TATA\n",
            "precision : 0.9605749486652977\n",
            "recall : 0.9027402547279043\n",
            "MCC : 0.8672622862846596\n",
            "Update best recall\n",
            "Update best MCC\n",
            "Epoch : 290 Experiment : human_non_TATA\n",
            "precision : 0.98\n",
            "recall : 0.8888460054033192\n",
            "MCC : 0.8744974343655129\n",
            "Update best MCC\n",
            "Epoch : 300 Experiment : human_non_TATA\n",
            "precision : 0.9739495798319328\n",
            "recall : 0.8946352759552296\n",
            "MCC : 0.8736078972296186\n",
            "Epoch : 310 Experiment : human_non_TATA\n",
            "precision : 0.9658014009064689\n",
            "recall : 0.9046700115785411\n",
            "MCC : 0.8743893767524366\n",
            "Update best recall\n",
            "Epoch : 320 Experiment : human_non_TATA\n",
            "precision : 0.9657731958762886\n",
            "recall : 0.9038981088382864\n",
            "MCC : 0.8736590427326446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ieTpMZZWWCE-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}